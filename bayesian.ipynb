{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.ChartMap import chart_type, agg_type\n",
    "from vega_datasets import data\n",
    "\n",
    "from src.oracle import ColumbusOracle, OracleWeight, OracleResult\n",
    "from src.generator.Generator import (\n",
    "    Explorer,\n",
    "    SamplingWeight,\n",
    "    VisualizationNode,\n",
    ")\n",
    "from IPython.display import clear_output\n",
    "from collections import Counter\n",
    "import altair as alt\n",
    "\n",
    "df = data.movies()\n",
    "df = df[[\n",
    "    col\n",
    "    for col in df.columns\n",
    "    if (df[col].dtype == \"object\" and df[col].nunique() < 10)\n",
    "    or df[col].dtype != \"object\"\n",
    "]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "101\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 143\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(norm_maxs))\n\u001b[1;32m    142\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(n_charts))\n\u001b[0;32m--> 143\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(\n\u001b[1;32m    144\u001b[0m     {\n\u001b[1;32m    145\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mepoch\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mrange\u001b[39;49m(epoch\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[1;32m    146\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mraw_means\u001b[39;49m\u001b[39m\"\u001b[39;49m: raw_means,\n\u001b[1;32m    147\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mraw_max\u001b[39;49m\u001b[39m\"\u001b[39;49m: raw_maxs,\n\u001b[1;32m    148\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mnorm_means\u001b[39;49m\u001b[39m\"\u001b[39;49m: norm_means,\n\u001b[1;32m    149\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mnorm_max\u001b[39;49m\u001b[39m\"\u001b[39;49m: norm_maxs,\n\u001b[1;32m    150\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mn_charts\u001b[39;49m\u001b[39m\"\u001b[39;49m: n_charts\n\u001b[1;32m    151\u001b[0m     }\n\u001b[1;32m    152\u001b[0m )\n\u001b[1;32m    153\u001b[0m line \u001b[39m=\u001b[39m alt\u001b[39m.\u001b[39mChart(data)\u001b[39m.\u001b[39mmark_line()\u001b[39m.\u001b[39mencode(\n\u001b[1;32m    154\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m )\n\u001b[1;32m    156\u001b[0m clear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/columbus/lib/python3.10/site-packages/pandas/core/frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    658\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[1;32m    659\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    660\u001b[0m     )\n\u001b[1;32m    662\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    663\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 664\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[1;32m    665\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[1;32m    666\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/columbus/lib/python3.10/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/miniforge3/envs/columbus/lib/python3.10/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    119\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/miniforge3/envs/columbus/lib/python3.10/site-packages/pandas/core/internals/construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[1;32m    665\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 666\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    668\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[1;32m    669\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    670\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    671\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "oracle_weight = OracleWeight(\n",
    "    specificity=1.0,\n",
    "    interestingness=1.0,\n",
    "    diversity=1.0,\n",
    "    coverage=2.0,\n",
    "    conciseness=1.0,\n",
    ")\n",
    "oracle = ColumbusOracle(df, oracle_weight)\n",
    "expl = Explorer(df)\n",
    "\n",
    "\n",
    "\n",
    "attr_names = [None if attr == None else attr.name for attr in expl.attrs]\n",
    "\n",
    "\n",
    "n_epoch = 1000\n",
    "n_dashboards = 100\n",
    "halving = 0.1\n",
    "\n",
    "raw_means = []\n",
    "raw_maxs = []\n",
    "norm_means = []\n",
    "norm_maxs = []\n",
    "\n",
    "n_charts = []\n",
    "\n",
    "conjugate_priors = SamplingWeight(\n",
    "    x=np.ones(len(attr_names)),\n",
    "    y=np.ones(len(attr_names)),\n",
    "    z=np.ones(len(attr_names)),\n",
    "    ct=np.ones(len(chart_type)),\n",
    "    at=np.ones(len(agg_type)),\n",
    "    n_chart=8.0,\n",
    ")\n",
    "\n",
    "def mean(l):\n",
    "    return sum(l) / len(l)\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    \n",
    "    n_charts = [max(np.random.normal(conjugate_priors.n_chart, 1), 2) for _ in range(n_dashboards)]\n",
    "    candidate: list[list[VisualizationNode]] = [expl.sample_n(round(n_chart), conjugate_priors) for n_chart in n_charts]\n",
    "    \n",
    "    \n",
    "    results: list[OracleResult] = [oracle.get_result(dashboard, set([\"IMDB_Votes\", \"boxplot\"])) for dashboard in candidate]\n",
    "    \n",
    "    \n",
    "    specificity = np.array([result.specificity for result in results])\n",
    "    interestingness = np.array([result.interestingness for result in results])\n",
    "    conciseness = np.array([result.conciseness for result in results])\n",
    "    \n",
    "    diversity = np.array([result.diversity for result in results])\n",
    "    coverage = np.array([result.coverage for result in results])\n",
    "    \n",
    "    raw_scores = specificity +  interestingness + conciseness + diversity + coverage\n",
    "    \n",
    "    # z normalize each scores\n",
    "    norm_specificity = (specificity - specificity.mean()) / specificity.std()\n",
    "    norm_interestingness = (interestingness - interestingness.mean()) / interestingness.std()\n",
    "    norm_conciseness = (conciseness - conciseness.mean()) / conciseness.std()\n",
    "    norm_diversity = (diversity - diversity.mean()) / diversity.std()\n",
    "    norm_coverage = (coverage - coverage.mean()) / coverage.std()\n",
    "    \n",
    "    normalized_scores = norm_specificity +  norm_interestingness + norm_conciseness + norm_diversity + norm_coverage\n",
    "    # normalized_scores = list(normalized_scores)\n",
    "    \n",
    "    \n",
    "    candi_n_score = list(zip(candidate, normalized_scores))\n",
    "    candi_n_score = sorted(candi_n_score, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    \n",
    "    raw_maxs.append(raw_scores.max())\n",
    "    raw_means.append(raw_scores.mean())\n",
    "    norm_maxs.append(normalized_scores.max())\n",
    "    norm_means.append(normalized_scores.mean())\n",
    "    \n",
    "    # halving\n",
    "    halved_candidate = candi_n_score[: int(n_dashboards * halving)]\n",
    "    \n",
    "    counters = [Counter() for _ in range(5)]\n",
    "    counters[0][None] = 0\n",
    "    counters[1][None] = 0\n",
    "    counters[2][None] = 0\n",
    "    \n",
    "    halved_n_charts = []\n",
    "    \n",
    "    \n",
    "    for dashboard in halved_candidate:\n",
    "        halved_n_charts.append(len(dashboard[0]))\n",
    "        for s in dashboard[0]:           \n",
    "            ct, x, y, z, at = s.sample\n",
    "            chart = [x, y, z, ct, at]\n",
    "            \n",
    "            for i in range(3):\n",
    "                if chart[i] is None:\n",
    "                    counters[i][None] += 1\n",
    "                elif chart[i].name in counters[i]:\n",
    "                    counters[i][chart[i].name] += 1\n",
    "                else:\n",
    "                    counters[i][chart[i].name] = 1\n",
    "\n",
    "            for i in [3,4]:\n",
    "                if chart[i] in counters[i]:\n",
    "                    counters[i][chart[i]] += 1\n",
    "                else:\n",
    "                    counters[i][chart[i]] = 1\n",
    "    \n",
    "    # update conjucate prior with liklihood by counter\n",
    "    x = np.array([counters[0][attr] for attr in attr_names])\n",
    "    y = np.array([counters[1][attr] for attr in attr_names])\n",
    "    z = np.array([counters[2][attr] for attr in attr_names])\n",
    "    ct = np.array([counters[3][c] for c in chart_type])\n",
    "    at = np.array([counters[4][a] for a in agg_type])\n",
    "    halved_n_charts = np.array(halved_n_charts)\n",
    "    \n",
    "    observed = int(n_dashboards * halving)\n",
    "    \n",
    "    prior_mean = conjugate_priors.n_chart\n",
    "    prior_var = 1\n",
    "    \n",
    "    halved_mean = halved_n_charts.mean()\n",
    "    halved_var = halved_n_charts.var()\n",
    "    \n",
    "    posterior_mean = (prior_mean / prior_var + halved_mean * observed / halved_var) / (1 / prior_var + observed / halved_var)\n",
    "    posterior_var = (1 / prior_var + observed / halved_var) ** -1\n",
    "    \n",
    "    conjugate_priors.x += x\n",
    "    conjugate_priors.y += y\n",
    "    conjugate_priors.z += z\n",
    "    conjugate_priors.ct += ct\n",
    "    conjugate_priors.at += at\n",
    "    conjugate_priors.n_chart =  posterior_mean\n",
    "    \n",
    "    n_charts.append(posterior_mean)\n",
    "    # visualize mean and max using altair\n",
    "   \n",
    "    print(len(range(epoch+1)))\n",
    "    print(len(raw_means))\n",
    "    print(len(raw_maxs))\n",
    "    print(len(norm_means))\n",
    "    print(len(norm_maxs))\n",
    "    print(len(n_charts))\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            \"epoch\": range(epoch+1),\n",
    "            \"raw_means\": raw_means,\n",
    "            \"raw_max\": raw_maxs,\n",
    "            \"norm_means\": norm_means,\n",
    "            \"norm_max\": norm_maxs,\n",
    "            \"n_charts\": n_charts\n",
    "        }\n",
    "    )\n",
    "    line = alt.Chart(data).mark_line().encode(\n",
    "        x=\"epoch\",\n",
    "    )\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    display(\n",
    "        line.encode(y=alt.Y(\"raw_means\", scale=alt.Scale(zero=False))) |\n",
    "        line.encode(y=alt.Y(\"raw_max\",scale=alt.Scale(zero=False))) |\n",
    "        line.encode(y=alt.Y(\"n_charts\",scale=alt.Scale(zero=False))) \n",
    "        )\n",
    "    display(pd.DataFrame(conjugate_priors.x / conjugate_priors.x.sum(), index=attr_names).T)\n",
    "    display(pd.DataFrame(conjugate_priors.y / conjugate_priors.y.sum(), index=attr_names).T)\n",
    "    display(pd.DataFrame(conjugate_priors.z / conjugate_priors.z.sum(), index=attr_names).T)\n",
    "    display(pd.DataFrame(conjugate_priors.ct / conjugate_priors.ct.sum(), index=chart_type).T)\n",
    "    display(pd.DataFrame(conjugate_priors.at / conjugate_priors.at.sum(), index=agg_type).T)\n",
    "\n",
    "    display(pd.DataFrame([specificity.mean(), interestingness.mean(), conciseness.mean(), diversity.mean(), coverage.mean()], index=[\"specificity\", \"interestingness\", \"conciseness\", \"diversity\", \"coverage\"]).T)\n",
    "    display(pd.DataFrame([specificity.max(), interestingness.max(), conciseness.max(), diversity.max(), coverage.max()], index=[\"specificity\", \"interestingness\", \"conciseness\", \"diversity\", \"coverage\"]).T)\n",
    "    \n",
    "    maxnodes: list[VisualizationNode] = candi_n_score[0][0]\n",
    "    max_res = oracle.get_result(maxnodes, set([\"IMDB_Votes\", \"boxplot\"]))\n",
    "    print(max_res)\n",
    "    altairs = [node.get_altair().properties(width=100, height=100) for node in maxnodes]\n",
    "\n",
    "    rows: list[alt.HConcatChart] = [\n",
    "        alt.hconcat(*altairs[i : i + 4]).resolve_scale(\n",
    "            color=\"independent\"\n",
    "        )\n",
    "        for i in range(0, len(altairs), 4)\n",
    "    ]\n",
    "    display(alt.vconcat(*rows))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed counts: [3 3 4]\n",
      "Posterior parameters: [5 1 4]\n",
      "New counts: [5 1 4]\n",
      "[0 1 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import dirichlet, multinomial\n",
    "\n",
    "# Define the Dirichlet prior parameters\n",
    "alpha = [1, 1, 1]\n",
    "\n",
    "# Generate some data from a Multinomial distribution\n",
    "n = 10\n",
    "p = [0.3, 0.4, 0.3] # true probabilities\n",
    "counts = multinomial(n, p)\n",
    "\n",
    "new_counts = multinomial(n, dirichlet(alpha + counts))\n",
    "\n",
    "print(\"Observed counts:\", counts)\n",
    "print(\"Posterior parameters:\", new_counts)\n",
    "print(\"New counts:\", new_counts)\n",
    "\n",
    "\n",
    "\n",
    "print(multinomial(1, dirichlet(alpha + counts)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "columbus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
